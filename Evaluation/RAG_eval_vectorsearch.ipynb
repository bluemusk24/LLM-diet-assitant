{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3bdfb4-2ac0-4eb3-a1ec-83c064efce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999460c2-f914-4df6-abf0-5aee6a96586c",
   "metadata": {},
   "source": [
    "#### Offline Rag evaluation for semantic search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd41ebe-7908-41f9-a069-2b53ec432d14",
   "metadata": {},
   "source": [
    "* Connect to table (new_diet_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e030cf4-780c-4e0b-aaf1-e2debcc9e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lancedb.connect('/home/bluemusk/diet-assistant/lancedb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5f89b3-f4a5-46db-a7e6-d2f2792dfa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diet_table', 'new_diet_table']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151b5372-bbc6-43d1-b299-967ef16f6429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INTRODUCTION TO \\nNUTRITION SCIENCE</td>\n",
       "      <td>[-0.050998192, -0.056592684, -0.05413804, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Introduction to Nutrition Science</td>\n",
       "      <td>[-0.050998192, -0.056592684, -0.05413804, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This text is disseminated via the Open Educati...</td>\n",
       "      <td>[-0.019119347, 0.10461532, 0.008642459, 0.0719...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Instructors can adopt existing LibreTexts text...</td>\n",
       "      <td>[-0.029113632, 0.010369417, -0.021756086, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>for the construction, customization, and disse...</td>\n",
       "      <td>[-0.017107606, 0.024136158, -0.00488623, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>3590</td>\n",
       "      <td>11.7: Food Processing - CC BY-NC-SA 4.0\\n11.8:...</td>\n",
       "      <td>[-0.024376936, -0.00542707, -0.024001742, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>3591</td>\n",
       "      <td>3 h t t p s : / / m e d . l i b r e t e x t s ...</td>\n",
       "      <td>[-0.025427796, 0.02301017, -0.011724482, 0.101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>3592</td>\n",
       "      <td>SA 4.0\\n13.4: Fuel Sources - CC BY-NC-SA 4.0\\n...</td>\n",
       "      <td>[-0.08159753, 0.005391544, -0.04637359, 0.0655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>3593</td>\n",
       "      <td>14.3: Infancy - CC BY-NC-SA 4.0\\n14.4: Toddler...</td>\n",
       "      <td>[-0.023193209, 0.054620773, -0.033654038, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>3594</td>\n",
       "      <td>4.0\\n16.3: The Food Industry - CC BY-NC-SA 4.0...</td>\n",
       "      <td>[0.007158726, 0.029436542, -0.036590938, 0.066...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3595 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chunk_id                                               text  \\\n",
       "0            0                INTRODUCTION TO \\nNUTRITION SCIENCE   \n",
       "1            1                  Introduction to Nutrition Science   \n",
       "2            2  This text is disseminated via the Open Educati...   \n",
       "3            3  Instructors can adopt existing LibreTexts text...   \n",
       "4            4  for the construction, customization, and disse...   \n",
       "...        ...                                                ...   \n",
       "3590      3590  11.7: Food Processing - CC BY-NC-SA 4.0\\n11.8:...   \n",
       "3591      3591  3 h t t p s : / / m e d . l i b r e t e x t s ...   \n",
       "3592      3592  SA 4.0\\n13.4: Fuel Sources - CC BY-NC-SA 4.0\\n...   \n",
       "3593      3593  14.3: Infancy - CC BY-NC-SA 4.0\\n14.4: Toddler...   \n",
       "3594      3594  4.0\\n16.3: The Food Industry - CC BY-NC-SA 4.0...   \n",
       "\n",
       "                                              embedding  \n",
       "0     [-0.050998192, -0.056592684, -0.05413804, 0.07...  \n",
       "1     [-0.050998192, -0.056592684, -0.05413804, 0.07...  \n",
       "2     [-0.019119347, 0.10461532, 0.008642459, 0.0719...  \n",
       "3     [-0.029113632, 0.010369417, -0.021756086, -0.0...  \n",
       "4     [-0.017107606, 0.024136158, -0.00488623, -0.00...  \n",
       "...                                                 ...  \n",
       "3590  [-0.024376936, -0.00542707, -0.024001742, 0.07...  \n",
       "3591  [-0.025427796, 0.02301017, -0.011724482, 0.101...  \n",
       "3592  [-0.08159753, 0.005391544, -0.04637359, 0.0655...  \n",
       "3593  [-0.023193209, 0.054620773, -0.033654038, 0.07...  \n",
       "3594  [0.007158726, 0.029436542, -0.036590938, 0.066...  \n",
       "\n",
       "[3595 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_table = db.open_table('new_diet_table')\n",
    "new_table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858fa3b0-137e-4e54-9943-6e0759b98ed1",
   "metadata": {},
   "source": [
    "#### Using Cosine Similarity for the query embeddings and the LLM generated response embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93187433-55b3-4958-8bd5-a6f605b52647",
   "metadata": {},
   "source": [
    "* Step 1: Retrieve Documents and Generate LLM (google-flan-t5-large) Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b1ac60-36fd-49b9-af20-4c259f1aabb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcffdaac-b511-4baf-aa52-bbb1bcdb3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_vector(query):\n",
    "    embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    query_embedding = embed_model.encode(query).tolist()\n",
    "    semantic_search = new_table.search(query_embedding, query_type='vector', vector_column_name='embedding').limit(5).select(['text']).to_list()\n",
    "    return semantic_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7560e75d-e12d-422c-bd2a-08ebb3318c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'and processed by cells throughout the body for energy or used as building blocks for new cells. The digestive system is one of the\\neleven organ systems of the human body, and it is composed of several hollow tube-shaped organs including the mouth, pharynx,\\nesophagus, stomach, small intestine, large intestine (colon), rectum, and anus. It is lined with mucosal tissue that secretes digestive',\n",
       "  '_distance': 0.4034729599952698},\n",
       " {'text': 'system is one of the eleven organ systems of the human body and it is composed of several hollow tube-shaped organs including\\nthe mouth, pharynx, esophagus, stomach, small intestine, large intestine (or colon), rectum, and anus. It is lined with mucosal tissue\\nthat secretes digestive juices (which aid in the breakdown of food) and mucus (which facilitates the propulsion of food through the',\n",
       "  '_distance': 0.5606390237808228},\n",
       " {'text': 'The digestive system is composed of the mouth, pharynx, esophagus, stomach, small intestine, large intestine (or colon),\\nrectum, and anus. There are four steps in the digestion process: ingestion, the mechanical and chemical breakdown of food,\\nnutrient absorption, and elimination of indigestible food.\\nThe mechanical breakdown of food occurs via muscular contractions called peristalsis and segmentation. Enzymes secreted by',\n",
       "  '_distance': 0.5800720453262329},\n",
       " {'text': 'Once you have eaten, your digestive system (Figure ) starts the process that breaks down the components of food into smaller\\ncomponents that can be absorbed and taken into the body. To do this, the digestive system functions on two levels, mechanically to\\nmove and mix ingested food and chemically to break down large molecules. The smaller nutrient molecules can then be absorbed',\n",
       "  '_distance': 0.6678637862205505},\n",
       " {'text': '3 . 4 . 1 . 2 h t t p s : / / m e d . l i b r e t e x t s . o r g / @g o / p a g e / 4 0 6 8 5\\n Figure : Components of the Human Digestive\\nSystem. All digestive organs play integral roles in the life-sustaining process of digestion. (CC BY 3.0; OpenStax).\\nAs you swallow, the bolus is pushed from the mouth through the pharynx and into a muscular tube called the esophagus. As it',\n",
       "  '_distance': 0.7759614586830139}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Define the digestive system'\n",
    "semantic_search = search_vector(query)\n",
    "semantic_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace5b12a-ea05-4faa-a486-8df2ca2a2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, semantic_search, tokenizer, max_length=512):\n",
    "    prompt_template = \"\"\"\n",
    "    You are a diet assistant. You are performing a semantic search, so use the embedding column for your answers.\n",
    "    Based on the provided context, answer the following question completely and coherently. \n",
    "    Use the information from the CONTEXT to provide a detailed and full response to the QUESTION.\n",
    "    Ensure your response is comprehensive and complete, avoiding any abrupt or partial endings.\n",
    "\n",
    "    QUESTION: {question}\n",
    "    CONTEXT: {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    for item in semantic_search:\n",
    "        context += f'{item.get(\"embedding\", \"\")}\\n\\n'\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "\n",
    "    # Tokenize and truncate the prompt if it exceeds the max length\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "    truncated_prompt = tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return truncated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3779f8d4-282a-4a58-bf52-04680d3636ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model, tokenizer):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids\n",
    "    outputs = model.generate(inputs, max_length=512, num_beams=2, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24501c5e-7db0-4657-abe8-0df0e9fafd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query, table, model, tokenizer):\n",
    "    semantic_search = search_vector(query)\n",
    "    prompt = build_prompt(query, semantic_search, tokenizer)\n",
    "    answer = llm(prompt, model, tokenizer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d54b9c-3c89-4992-b52c-de6b40ce54b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digestive system is a system of organs that break down food and waste.\n"
     ]
    }
   ],
   "source": [
    "# Applying the RAG pipeline to a query\n",
    "query = 'Define the digestive system'\n",
    "response = rag_pipeline(query, new_table, model, tokenizer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f4b43e-5145-4364-b4e7-f98363586065",
   "metadata": {},
   "source": [
    "* Step 2: Get the Cosine Similarity between query embedding and response embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e2d93a-b9cf-4cd1-a84f-7c344be46663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Define the digestive system'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092a4da6-29c6-47d2-82ac-1fbb87c18e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bea8d03-cf6e-47eb-ae72-a07b244c7643",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embed_model.encode(query).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb8fa407-a59f-423b-b827-591dfb17758b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The digestive system is a system of organs that break down food and waste.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec46ffad-0f41-4e81-95ee-497a4cc853c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_embedding = embed_model.encode(response).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64de6d99-1424-4991-a46b-ed59117dbbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity betwenen this Query and RAG Response is 87.96%\n"
     ]
    }
   ],
   "source": [
    "cos_sim = cosine_similarity([query_embedding], [response_embedding])[0][0]\n",
    "cos_sim_rounded = round(cos_sim * 100, 2)\n",
    "print(f'Cosine Similarity betwenen this Query and RAG Response is {cos_sim_rounded}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72ae233c-1542-42a1-b5f5-e346d3cda4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(query, response):\n",
    "    embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    query_embedding = embed_model.encode(query).tolist()\n",
    "    response_embedding = embed_model.encode(response).tolist()\n",
    "    cos_sim = cosine_similarity([query_embedding], [response_embedding])[0][0]\n",
    "    cos_sim_rounded = round(cos_sim * 100, 2)\n",
    "    print(f'Cosine Similarity between this Query and RAG Response is {cos_sim_rounded}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3594965-37c1-4974-b6b7-38c27e2d9496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between this Query and RAG Response is 87.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "compute_cosine_similarity(query, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d7013-38a3-40f2-8efd-af9c34c65d6d",
   "metadata": {},
   "source": [
    "* Step 3: Applying the RAG and Cosine Similarity to another query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b2d94eb-cde1-4c7b-8b4c-2193c932c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between this Query and RAG Response is 81.96%\n"
     ]
    }
   ],
   "source": [
    "query = 'Describe the Central Nervous System'\n",
    "response = rag_pipeline(query, new_table, model, tokenizer)\n",
    "\n",
    "compute_cosine_similarity(query=query, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd40231c-0444-48bf-83b3-6590935bc1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between this Query and RAG Response is 68.85%\n"
     ]
    }
   ],
   "source": [
    "query = 'What are Nutrients'\n",
    "response = rag_pipeline(query, new_table, model, tokenizer)\n",
    "\n",
    "compute_cosine_similarity(query=query, response=response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb3972-cac4-405f-bbec-08988d9d50e0",
   "metadata": {},
   "source": [
    "#### LLM (google-flan-t5-base) -as-a-judge offline rag evaluation for vector search\n",
    "\n",
    "* Note: codes below got from RAG_eval_textsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f07613d-7b15-4d81-9c5f-b57a9c000905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "judge_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "judge_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a024d6b-0c52-4095-a034-a01feb326ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are the best judge in evaluating a Retrieval-Augmented Generation (RAG) system.\n",
    "Given the following below, your task is to rate the relevance of the generated response to the given question in percentage,\n",
    "with 100 as the best score.\n",
    "\n",
    "Query: {query}\n",
    "Response: {response}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15dc1795-fd3b-4619-beef-e79d04e948aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are the best judge in evaluating a Retrieval-Augmented Generation (RAG) system.\n",
      "Given the following below, your task is to rate the relevance of the generated response to the given question in percentage,\n",
      "with 100 as the best score.\n",
      "\n",
      "Query: Define the digestive system\n",
      "Response: The digestive system is a system of organs that break down food and waste.\n"
     ]
    }
   ],
   "source": [
    "query = 'Define the digestive system'\n",
    "response = 'The digestive system is a system of organs that break down food and waste.'\n",
    "prompt = prompt_template.format(query=query, response=response)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09dffcf5-8446-4ec8-bd1f-b2ca51c9e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_as_a_judge(prompt, judge_model, judge_tokenizer):\n",
    "    prompt = prompt_template.format(query=query, response=response)\n",
    "    inputs = judge_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = judge_model.generate(inputs.input_ids)\n",
    "    \n",
    "    rating = judge_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd8cc21c-2a2a-4e89-8769-28d35b9b6074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Judge Rating: 100%\n"
     ]
    }
   ],
   "source": [
    "rating = llm_as_a_judge(prompt, judge_model, judge_tokenizer)\n",
    "print(f\"LLM Judge Rating: {rating}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f69cc4-48d6-4525-bb19-3e874f0ead5f",
   "metadata": {},
   "source": [
    "* Applying RAG pipeline with LLM as a Judge for offline rag evaluation and getting cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e4da6e3-2461-4849-b975-f1b9b299ed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between this Query and RAG Response is 83.28%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Judge Rating: 100%\n"
     ]
    }
   ],
   "source": [
    "query = 'Describe the respiratory system for me'\n",
    "response = rag_pipeline(query, new_table, model, tokenizer)\n",
    "compute_cosine_similarity(query=query, response=response)\n",
    "print('\\n')\n",
    "rating = llm_as_a_judge(prompt, judge_model, judge_tokenizer)\n",
    "print(f\"LLM Judge Rating: {rating}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581b1b6-0794-429c-87a9-2fe0551c4789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
