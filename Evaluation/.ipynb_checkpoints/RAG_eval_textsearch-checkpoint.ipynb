{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4a10d7-5b68-4815-9125-c2efd15db4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0871b9-68f9-46b4-a7f7-d41b2ca4fe1d",
   "metadata": {},
   "source": [
    "#### Offline Rag evaluation for text_search \n",
    "\n",
    "* Step 1: connect lancedb and open table (diet_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca6b0a61-e93b-49fb-9cf3-c2132bf2fa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diet_table', 'new_diet_table']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = lancedb.connect('/home/bluemusk/diet-assistant/lancedb')\n",
    "\n",
    "db.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f96ccdd8-6789-4815-840a-e8255c9c12b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INTRODUCTION TO \\nNUTRITION SCIENCE</td>\n",
       "      <td>[-0.05099819228053093, -0.056592684239149094, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Introduction to Nutrition Science</td>\n",
       "      <td>[-0.05099819228053093, -0.056592684239149094, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This text is disseminated via the Open Educati...</td>\n",
       "      <td>[-0.019119346514344215, 0.10461532324552536, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Instructors can adopt existing LibreTexts text...</td>\n",
       "      <td>[-0.029113631695508957, 0.010369417257606983, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>for the construction, customization, and disse...</td>\n",
       "      <td>[-0.017107605934143066, 0.02413615770637989, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>3590</td>\n",
       "      <td>11.7: Food Processing - CC BY-NC-SA 4.0\\n11.8:...</td>\n",
       "      <td>[-0.02437693625688553, -0.005427069962024689, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>3591</td>\n",
       "      <td>3 h t t p s : / / m e d . l i b r e t e x t s ...</td>\n",
       "      <td>[-0.025427795946598053, 0.023010170087218285, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>3592</td>\n",
       "      <td>SA 4.0\\n13.4: Fuel Sources - CC BY-NC-SA 4.0\\n...</td>\n",
       "      <td>[-0.08159752935171127, 0.005391544196754694, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>3593</td>\n",
       "      <td>14.3: Infancy - CC BY-NC-SA 4.0\\n14.4: Toddler...</td>\n",
       "      <td>[-0.023193208500742912, 0.05462077260017395, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>3594</td>\n",
       "      <td>4.0\\n16.3: The Food Industry - CC BY-NC-SA 4.0...</td>\n",
       "      <td>[0.007158725988119841, 0.029436541721224785, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3595 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chunk_id                                               text  \\\n",
       "0            0                INTRODUCTION TO \\nNUTRITION SCIENCE   \n",
       "1            1                  Introduction to Nutrition Science   \n",
       "2            2  This text is disseminated via the Open Educati...   \n",
       "3            3  Instructors can adopt existing LibreTexts text...   \n",
       "4            4  for the construction, customization, and disse...   \n",
       "...        ...                                                ...   \n",
       "3590      3590  11.7: Food Processing - CC BY-NC-SA 4.0\\n11.8:...   \n",
       "3591      3591  3 h t t p s : / / m e d . l i b r e t e x t s ...   \n",
       "3592      3592  SA 4.0\\n13.4: Fuel Sources - CC BY-NC-SA 4.0\\n...   \n",
       "3593      3593  14.3: Infancy - CC BY-NC-SA 4.0\\n14.4: Toddler...   \n",
       "3594      3594  4.0\\n16.3: The Food Industry - CC BY-NC-SA 4.0...   \n",
       "\n",
       "                                              embedding  \n",
       "0     [-0.05099819228053093, -0.056592684239149094, ...  \n",
       "1     [-0.05099819228053093, -0.056592684239149094, ...  \n",
       "2     [-0.019119346514344215, 0.10461532324552536, 0...  \n",
       "3     [-0.029113631695508957, 0.010369417257606983, ...  \n",
       "4     [-0.017107605934143066, 0.02413615770637989, -...  \n",
       "...                                                 ...  \n",
       "3590  [-0.02437693625688553, -0.005427069962024689, ...  \n",
       "3591  [-0.025427795946598053, 0.023010170087218285, ...  \n",
       "3592  [-0.08159752935171127, 0.005391544196754694, -...  \n",
       "3593  [-0.023193208500742912, 0.05462077260017395, -...  \n",
       "3594  [0.007158725988119841, 0.029436541721224785, -...  \n",
       "\n",
       "[3595 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = db.open_table('diet_table')\n",
    "table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b8456-2c42-4798-9fa6-3abf43e9271a",
   "metadata": {},
   "source": [
    "* Step 2: Retrieve Documents and Generate LLM (google-flan-t5-large) Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0669aca6-636c-4901-81b1-478fa7a24b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b07ecf-1e2e-4a95-aaa4-f0e04c3e8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    text_search = table.search(query, query_type=\"fts\").limit(5).select([\"text\"]).to_list()\n",
    "    return text_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb3a92a4-c47f-4d06-a70c-cea9735658c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Expand Y our Knowledge  \\n1. Write a short script for a public service announcement that explains the benefits and risks of food additives. What do you\\nbelieve the public should know about the natural and synthetic substances that are introduced to foods during the processing\\nstage?\\n2. Summarize in a written discussion why economic experts believe the era of cheap food is over. What factors have contributed to\\nrising food prices around the globe?',\n",
       "  '_score': 10.872123718261719},\n",
       " {'text': 'Food Preservation and Processing  \\nTwo important aspects of a food system are preservation and processing. Each provides for or protects consumers in different ways.\\nFood preservation includes the handling or treating of food to prevent or slow down spoilage. Food processing involves\\ntransforming raw ingredients into packaged food, from fresh-baked goods to frozen dinners. Although there are numerous benefits',\n",
       "  '_score': 9.493345260620117},\n",
       " {'text': '11.6: Food Preservation\\n11.7: Food Processing\\n11.8: The Effect of New Technologies\\n11.9: Efforts on the Consumer Level- What You Can Do\\nThis page titled 11: Food Safety is shared under a CC BY-NC-SA 4.0 license and was authored, remixed, and/or curated by Jennifer Draper,\\nMarie Kainoa Fialkowski Revilla, & Alan Titchenal via source content that was edited to the style and standards of the LibreTexts platform; a\\ndetailed edit history is available upon request.Learning Objectives',\n",
       "  '_score': 9.43094539642334},\n",
       " {'text': 'as a line of cupcakes packaged and sold in stores.\\nThe Pros and Cons of Food Processing  \\nFood processing has a number of important benefits, such as creating products that have a much longer shelf life than raw foods.\\nAlso, food processing protects the health of the consumer and allows for easier shipment and the marketing of foods by\\ncorporations. However, there are certain drawbacks. Food processing can reduce the nutritional content of raw ingredients. For',\n",
       "  '_score': 9.400575637817383},\n",
       " {'text': 'crop cultivation to manufacturing and processing, from marketing and advertising to distribution and shipment, to food regulation.\\nThe Food System  \\nThe food system is a network of farmers and related operations, including food processing, wholesale and distribution, retail,\\nindustry technology, and marketing. The milk industry, for example, includes everything from the farm that raises livestock, to the',\n",
       "  '_score': 9.255035400390625}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What is food processing?'\n",
    "text_search = search(query)\n",
    "text_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad2be104-b611-473f-ad06-7d2f78f0ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, text_search, tokenizer, max_length=512):\n",
    "    prompt_template = \"\"\"\n",
    "    You are a diet assistant. You're performing a full text search, so use the text column only for answers.\n",
    "    Based on the provided context, answer the following question completely and coherently. \n",
    "    Use the information from the CONTEXT to provide a detailed and full response to the QUESTION.\n",
    "    Ensure your response is comprehensive and complete, avoiding any abrupt or partial endings.\n",
    "\n",
    "    QUESTION: {question}\n",
    "    CONTEXT: {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    for item in text_search:\n",
    "        context += f'{item.get(\"text\", \"\")}\\n\\n'\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "\n",
    "    # Truncate prompt if it exceeds the model's max length\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "    truncated_prompt = tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return truncated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1902322-15ce-41d7-b868-4acdeba5d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model, tokenizer, max_tokens=72):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids\n",
    "    outputs = model.generate(inputs, max_new_tokens=max_tokens)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4ace2d2-e5d1-4887-b9ec-ae28a5773595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query, model, tokenizer):\n",
    "    text_search = search(query)\n",
    "    prompt = build_prompt(query, text_search, tokenizer)\n",
    "    answer = llm(prompt, model, tokenizer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d66ea5a-6dc0-4d8a-ac73-f07bb7963588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food processing involves transforming raw ingredients into packaged food, from fresh-baked goods to frozen dinners.\n"
     ]
    }
   ],
   "source": [
    "# Applying the RAG pipeline to this query\n",
    "query = 'What is food processing?'\n",
    "outcome = rag_pipeline(query, model, tokenizer)\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b7e0f-6b17-4e2d-ab39-a0e10775794c",
   "metadata": {},
   "source": [
    "##### Exact match offline rag evaluation for text search using Precision and Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ecb408ac-9036-4acf-b0f3-e5f412d93a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match_evaluation(query, response):\n",
    "    query_tokens = set(query.lower().split())  \n",
    "    response_tokens = set(response.lower().split())  \n",
    "    \n",
    "    matches = query_tokens.intersection(response_tokens)\n",
    "    \n",
    "    precision = len(matches) / len(response_tokens) if response_tokens else 0\n",
    "    recall = len(matches) / len(query_tokens) if query_tokens else 0\n",
    "\n",
    "    print(f'The exact match of the query_tokens and response_tokens is {matches}')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "834836f8-1b81-4044-81a7-6ded0aa822cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact match of the query_tokens and response_tokens is {'food'}\n",
      "Precision: 0.07, Recall: 0.25\n"
     ]
    }
   ],
   "source": [
    "query = 'What is food processing?'\n",
    "response = 'Food processing involves transforming raw ingredients into packaged food, from fresh-baked goods to frozen dinners.'\n",
    "\n",
    "precision, recall = exact_match_evaluation(query, response)\n",
    "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f669bc-7602-4c37-b012-da8d00205b60",
   "metadata": {},
   "source": [
    "* Applying RAG pipeline with exact match, precision and recall offline rag evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e14069b1-f9a4-4221-815f-4670dacc4ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact match of the query_tokens and response_tokens is {'nutrients', 'are'}\n",
      "Precision: 0.05, Recall: 0.67\n"
     ]
    }
   ],
   "source": [
    "query = 'What are nutrients'\n",
    "response = rag_pipeline(query, model, tokenizer)\n",
    "\n",
    "precision, recall = exact_match_evaluation(query, response)\n",
    "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ce3f3-ced0-43b5-a3cd-f8d85f32f846",
   "metadata": {},
   "source": [
    "##### LLM (google-flan-t5-base) -as-a-judge offline rag evaluation for text search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c4604-020a-4c2e-ab21-f291dd61b24e",
   "metadata": {},
   "source": [
    "* Step 1: Download the Judge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1fb044a1-ba3e-4a16-9198-927e8b506e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa37bd5d66874ed3b4f48865455d6588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37de2d713240467da04a47ad62cc2ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fa6163a63a4bee81c18130f1780c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56ac1669261464ea75c284be0c0db31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a24702027d418b9b7a0e91cf051003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919ae20f0dca42708dbbad1c7071e66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4a66566aba4ec09a51b6b14fa99ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "judge_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "judge_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23920b02-ec35-4209-be77-6bdb5e32e431",
   "metadata": {},
   "source": [
    "* Step 2: Get the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e222ec48-69e8-4f2e-8519-e2b3ae17fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are the best judge in evaluating a Retrieval-Augmented Generation (RAG) system.\n",
    "Given the following below, your task is to rate the relevance of the generated response to the given question in percentage,\n",
    "with 100 as the best score.\n",
    "\n",
    "Query: {query}\n",
    "Response: {response}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c00e4c55-9f3a-4a90-ab9c-a5c8f0f69b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are the best judge in evaluating a Retrieval-Augmented Generation (RAG) system.\n",
      "Given the following below, your task is to rate the relevance of the generated response to the given question in percentage,\n",
      "with 100 as the best score.\n",
      "\n",
      "Query: What is food processing?\n",
      "Response: Food processing involves transforming raw ingredients into packaged food, from fresh-baked goods to frozen dinners.\n"
     ]
    }
   ],
   "source": [
    "query = 'What is food processing?'\n",
    "response = 'Food processing involves transforming raw ingredients into packaged food, from fresh-baked goods to frozen dinners.'\n",
    "prompt = prompt_template.format(query=query, response=response)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb8a94-4d89-4dd2-a08e-cd73e6f5e19d",
   "metadata": {},
   "source": [
    "* Step 3: Evaluate RAG with the LLM Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "603fcc47-0155-4513-a4fc-31c6c29f40a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_as_a_judge(prompt, judge_model, judge_tokenizer):\n",
    "    prompt = prompt_template.format(query=query, response=response)\n",
    "    inputs = judge_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = judge_model.generate(inputs.input_ids)\n",
    "    \n",
    "    rating = judge_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8da15d75-da47-4644-8b48-66462300aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Judge Rating: 100\n"
     ]
    }
   ],
   "source": [
    "rating = llm_as_a_judge(prompt, judge_model, judge_tokenizer)\n",
    "print(f\"LLM Judge Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c07da8-27cd-4cf8-88b4-6d49b7eb494c",
   "metadata": {},
   "source": [
    "* Step 4: Applying RAG pipeline with LLM as a Judge for offline rag evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9cb43b2-eb27-458b-88aa-bd29fcaf8216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluemusk/.local/share/virtualenvs/diet-assistant-eO1hxvO4/lib/python3.10/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Judge Rating: 100\n"
     ]
    }
   ],
   "source": [
    "query = 'What are nutrients'\n",
    "response = rag_pipeline(query, model, tokenizer)\n",
    "\n",
    "rating = llm_as_a_judge(prompt, judge_model, judge_tokenizer)\n",
    "print(f\"LLM Judge Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65950ce9-ea6a-4208-83fe-0c6f2f180395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
